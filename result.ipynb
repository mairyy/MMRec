{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Namespace(lr=0.001, seed=19260817, data='beauty', epoch=20, trn_batch=256, tst_batch=256, con_batch=2048, test_frequency=1, max_seq_len=50, num_reco_neg=40, reg=1e-06, ssl_reg=0.01, latdim=32, mask_depth=3, path_prob=0.5, num_attention_heads=4, num_gcn_layers=2, num_trm_layers=2, load_model=None, num_mask_cand=50, mask_steps=10, eps=0.2, attention_probs_dropout_prob=0.3, hidden_dropout_prob=0.3, save_path='tem')\n",
            "2023-12-12 03:35:59.194268: Start\n",
            "/content/drive/MyDrive/MAERec-v2-concate/handler.py:52: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:605.)\n",
            "  return t.sparse.FloatTensor(idxs, vals, shape).cuda()\n",
            "2023-12-12 03:36:04.907375: Load Data\n",
            "2023-12-12 03:36:04.907442: Users: 22363, Items(+1): 12101\n",
            "2023-12-12 03:36:06.751008: Model Prepared\n",
            "2023-12-12 03:36:06.751061: Model Initialized\n",
            "Test result: h5=0.0004 n5=0.0004 h10=0.0009 n10=0.0005 h20=0.0015 n20=0.0006 h50=0.0032 n50=0.0010\n",
            "2023-12-12 03:41:47.317724: Epoch 0/20, Train: loss = -49.2677, loss_main = 1.3035, loss_reco = -50.5287, loss_mask = -0.4715                   \n",
            "Test result: h5=0.0075 n5=0.0048 h10=0.0127 n10=0.0065 h20=0.0204 n20=0.0084 h50=0.0431 n50=0.0129\n",
            "2023-12-12 03:45:13.701137: Epoch 0/20, Test: hr@10 = 0.0127, ndcg@10 = 0.0065, hr@5 = 0.0075, ndcg@5 = 0.0048, hr@20 = 0.0204, ndcg@20 = 0.0084, hr@50 = 0.0431, ndcg@50 = 0.0129                   \n",
            "\u001b[1m2023-12-12 03:45:13.701187: Epoch 20/20, Best Result: hr@10 = 0.0127, ndcg@10 = 0.0065, hr@5 = 0.0075, ndcg@5 = 0.0048, hr@20 = 0.0204, ndcg@20 = 0.0084, hr@50 = 0.0431, ndcg@50 = 0.0129                   \u001b[0m\n",
            "2023-12-12 03:45:15.275293: Model Saved: tem\n",
            "\n",
            "2023-12-12 03:47:28.321973: Epoch 1/20, Train: loss = -50.4992, loss_main = 1.1791, loss_reco = -51.6414, loss_mask = -0.4113                   \n",
            "Test result: h5=0.0112 n5=0.0069 h10=0.0195 n10=0.0095 h20=0.0364 n20=0.0138 h50=0.0679 n50=0.0200\n",
            "2023-12-12 03:50:58.359904: Epoch 1/20, Test: hr@10 = 0.0195, ndcg@10 = 0.0095, hr@5 = 0.0112, ndcg@5 = 0.0069, hr@20 = 0.0364, ndcg@20 = 0.0138, hr@50 = 0.0679, ndcg@50 = 0.0200                   \n",
            "\u001b[1m2023-12-12 03:50:58.359970: Epoch 20/20, Best Result: hr@10 = 0.0195, ndcg@10 = 0.0095, hr@5 = 0.0112, ndcg@5 = 0.0069, hr@20 = 0.0364, ndcg@20 = 0.0138, hr@50 = 0.0679, ndcg@50 = 0.0200                   \u001b[0m\n",
            "2023-12-12 03:50:58.390867: Model Saved: tem\n",
            "\n",
            "2023-12-12 03:53:05.706242: Epoch 2/20, Train: loss = -63.3859, loss_main = 1.0651, loss_reco = -64.4151, loss_mask = -0.4124                   \n",
            "Test result: h5=0.0160 n5=0.0099 h10=0.0291 n10=0.0141 h20=0.0464 n20=0.0185 h50=0.0927 n50=0.0276\n",
            "2023-12-12 03:56:34.447179: Epoch 2/20, Test: hr@10 = 0.0291, ndcg@10 = 0.0141, hr@5 = 0.0160, ndcg@5 = 0.0099, hr@20 = 0.0464, ndcg@20 = 0.0185, hr@50 = 0.0927, ndcg@50 = 0.0276                   \n",
            "\u001b[1m2023-12-12 03:56:34.447244: Epoch 20/20, Best Result: hr@10 = 0.0291, ndcg@10 = 0.0141, hr@5 = 0.0160, ndcg@5 = 0.0099, hr@20 = 0.0464, ndcg@20 = 0.0185, hr@50 = 0.0927, ndcg@50 = 0.0276                   \u001b[0m\n",
            "2023-12-12 03:56:34.467926: Model Saved: tem\n",
            "\n",
            "2023-12-12 03:58:45.838591: Epoch 3/20, Train: loss = -75.3275, loss_main = 1.0025, loss_reco = -76.2722, loss_mask = -0.6599                   \n",
            "Test result: h5=0.0191 n5=0.0116 h10=0.0334 n10=0.0162 h20=0.0560 n20=0.0219 h50=0.1058 n50=0.0317\n",
            "2023-12-12 04:02:15.836831: Epoch 3/20, Test: hr@10 = 0.0334, ndcg@10 = 0.0162, hr@5 = 0.0191, ndcg@5 = 0.0116, hr@20 = 0.0560, ndcg@20 = 0.0219, hr@50 = 0.1058, ndcg@50 = 0.0317                   \n",
            "\u001b[1m2023-12-12 04:02:15.836921: Epoch 20/20, Best Result: hr@10 = 0.0334, ndcg@10 = 0.0162, hr@5 = 0.0191, ndcg@5 = 0.0116, hr@20 = 0.0560, ndcg@20 = 0.0219, hr@50 = 0.1058, ndcg@50 = 0.0317                   \u001b[0m\n",
            "2023-12-12 04:02:15.857512: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:04:26.569724: Epoch 4/20, Train: loss = -82.5279, loss_main = 0.9753, loss_reco = -83.4287, loss_mask = -0.8475                   \n",
            "Test result: h5=0.0224 n5=0.0135 h10=0.0396 n10=0.0189 h20=0.0607 n20=0.0242 h50=0.1145 n50=0.0348\n",
            "2023-12-12 04:07:53.811850: Epoch 4/20, Test: hr@10 = 0.0396, ndcg@10 = 0.0189, hr@5 = 0.0224, ndcg@5 = 0.0135, hr@20 = 0.0607, ndcg@20 = 0.0242, hr@50 = 0.1145, ndcg@50 = 0.0348                   \n",
            "\u001b[1m2023-12-12 04:07:53.811899: Epoch 20/20, Best Result: hr@10 = 0.0396, ndcg@10 = 0.0189, hr@5 = 0.0224, ndcg@5 = 0.0135, hr@20 = 0.0607, ndcg@20 = 0.0242, hr@50 = 0.1145, ndcg@50 = 0.0348                   \u001b[0m\n",
            "2023-12-12 04:07:53.832382: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:10:10.480433: Epoch 5/20, Train: loss = -86.5454, loss_main = 0.9526, loss_reco = -87.4397, loss_mask = -0.6757                   \n",
            "Test result: h5=0.0230 n5=0.0139 h10=0.0403 n10=0.0195 h20=0.0670 n20=0.0262 h50=0.1192 n50=0.0365\n",
            "2023-12-12 04:13:39.941604: Epoch 5/20, Test: hr@10 = 0.0403, ndcg@10 = 0.0195, hr@5 = 0.0230, ndcg@5 = 0.0139, hr@20 = 0.0670, ndcg@20 = 0.0262, hr@50 = 0.1192, ndcg@50 = 0.0365                   \n",
            "\u001b[1m2023-12-12 04:13:39.941662: Epoch 20/20, Best Result: hr@10 = 0.0403, ndcg@10 = 0.0195, hr@5 = 0.0230, ndcg@5 = 0.0139, hr@20 = 0.0670, ndcg@20 = 0.0262, hr@50 = 0.1192, ndcg@50 = 0.0365                   \u001b[0m\n",
            "2023-12-12 04:13:39.962472: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:15:50.906622: Epoch 6/20, Train: loss = -89.0310, loss_main = 0.9305, loss_reco = -89.9189, loss_mask = -0.5088                   \n",
            "Test result: h5=0.0256 n5=0.0154 h10=0.0436 n10=0.0212 h20=0.0713 n20=0.0282 h50=0.1260 n50=0.0390\n",
            "2023-12-12 04:19:23.015042: Epoch 6/20, Test: hr@10 = 0.0436, ndcg@10 = 0.0212, hr@5 = 0.0256, ndcg@5 = 0.0154, hr@20 = 0.0713, ndcg@20 = 0.0282, hr@50 = 0.1260, ndcg@50 = 0.0390                   \n",
            "\u001b[1m2023-12-12 04:19:23.015124: Epoch 20/20, Best Result: hr@10 = 0.0436, ndcg@10 = 0.0212, hr@5 = 0.0256, ndcg@5 = 0.0154, hr@20 = 0.0713, ndcg@20 = 0.0282, hr@50 = 0.1260, ndcg@50 = 0.0390                   \u001b[0m\n",
            "2023-12-12 04:19:23.041228: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:21:31.842991: Epoch 7/20, Train: loss = -91.4154, loss_main = 0.9137, loss_reco = -92.2717, loss_mask = -0.6718                   \n",
            "Test result: h5=0.0263 n5=0.0161 h10=0.0448 n10=0.0220 h20=0.0722 n20=0.0289 h50=0.1304 n50=0.0404\n",
            "2023-12-12 04:25:02.285355: Epoch 7/20, Test: hr@10 = 0.0448, ndcg@10 = 0.0220, hr@5 = 0.0263, ndcg@5 = 0.0161, hr@20 = 0.0722, ndcg@20 = 0.0289, hr@50 = 0.1304, ndcg@50 = 0.0404                   \n",
            "\u001b[1m2023-12-12 04:25:02.285453: Epoch 20/20, Best Result: hr@10 = 0.0448, ndcg@10 = 0.0220, hr@5 = 0.0263, ndcg@5 = 0.0161, hr@20 = 0.0722, ndcg@20 = 0.0289, hr@50 = 0.1304, ndcg@50 = 0.0404                   \u001b[0m\n",
            "2023-12-12 04:25:02.311654: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:27:07.843573: Epoch 8/20, Train: loss = -93.0481, loss_main = 0.8977, loss_reco = -93.9189, loss_mask = -0.3422                   \n",
            "Test result: h5=0.0278 n5=0.0169 h10=0.0463 n10=0.0228 h20=0.0730 n20=0.0296 h50=0.1332 n50=0.0414\n",
            "2023-12-12 04:30:41.237830: Epoch 8/20, Test: hr@10 = 0.0463, ndcg@10 = 0.0228, hr@5 = 0.0278, ndcg@5 = 0.0169, hr@20 = 0.0730, ndcg@20 = 0.0296, hr@50 = 0.1332, ndcg@50 = 0.0414                   \n",
            "\u001b[1m2023-12-12 04:30:41.237902: Epoch 20/20, Best Result: hr@10 = 0.0463, ndcg@10 = 0.0228, hr@5 = 0.0278, ndcg@5 = 0.0169, hr@20 = 0.0730, ndcg@20 = 0.0296, hr@50 = 0.1332, ndcg@50 = 0.0414                   \u001b[0m\n",
            "2023-12-12 04:30:41.258709: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:32:50.565964: Epoch 9/20, Train: loss = -94.0695, loss_main = 0.8831, loss_reco = -94.8898, loss_mask = -0.7327                   \n",
            "Test result: h5=0.0274 n5=0.0162 h10=0.0483 n10=0.0229 h20=0.0774 n20=0.0301 h50=0.1346 n50=0.0414\n",
            "2023-12-12 04:36:18.165991: Epoch 9/20, Test: hr@10 = 0.0483, ndcg@10 = 0.0229, hr@5 = 0.0274, ndcg@5 = 0.0162, hr@20 = 0.0774, ndcg@20 = 0.0301, hr@50 = 0.1346, ndcg@50 = 0.0414                   \n",
            "\u001b[1m2023-12-12 04:36:18.166100: Epoch 20/20, Best Result: hr@10 = 0.0483, ndcg@10 = 0.0229, hr@5 = 0.0274, ndcg@5 = 0.0162, hr@20 = 0.0774, ndcg@20 = 0.0301, hr@50 = 0.1346, ndcg@50 = 0.0414                   \u001b[0m\n",
            "2023-12-12 04:36:18.195069: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:38:27.435848: Epoch 10/20, Train: loss = -95.0984, loss_main = 0.8748, loss_reco = -95.9184, loss_mask = -0.6488                   \n",
            "Test result: h5=0.0280 n5=0.0168 h10=0.0478 n10=0.0232 h20=0.0767 n20=0.0304 h50=0.1376 n50=0.0424\n",
            "2023-12-12 04:41:56.096617: Epoch 10/20, Test: hr@10 = 0.0478, ndcg@10 = 0.0232, hr@5 = 0.0280, ndcg@5 = 0.0168, hr@20 = 0.0767, ndcg@20 = 0.0304, hr@50 = 0.1376, ndcg@50 = 0.0424                   \n",
            "\n",
            "2023-12-12 04:44:01.352166: Epoch 11/20, Train: loss = -95.6172, loss_main = 0.8675, loss_reco = -96.4145, loss_mask = -0.8176                   \n",
            "Test result: h5=0.0261 n5=0.0159 h10=0.0472 n10=0.0227 h20=0.0745 n20=0.0296 h50=0.1337 n50=0.0412\n",
            "2023-12-12 04:47:33.060791: Epoch 11/20, Test: hr@10 = 0.0472, ndcg@10 = 0.0227, hr@5 = 0.0261, ndcg@5 = 0.0159, hr@20 = 0.0745, ndcg@20 = 0.0296, hr@50 = 0.1337, ndcg@50 = 0.0412                   \n",
            "\n",
            "2023-12-12 04:49:40.198237: Epoch 12/20, Train: loss = -96.3943, loss_main = 0.8618, loss_reco = -97.2085, loss_mask = -0.5731                   \n",
            "Test result: h5=0.0287 n5=0.0175 h10=0.0495 n10=0.0241 h20=0.0758 n20=0.0307 h50=0.1370 n50=0.0428\n",
            "2023-12-12 04:53:09.990669: Epoch 12/20, Test: hr@10 = 0.0495, ndcg@10 = 0.0241, hr@5 = 0.0287, ndcg@5 = 0.0175, hr@20 = 0.0758, ndcg@20 = 0.0307, hr@50 = 0.1370, ndcg@50 = 0.0428                   \n",
            "\u001b[1m2023-12-12 04:53:09.990756: Epoch 20/20, Best Result: hr@10 = 0.0495, ndcg@10 = 0.0241, hr@5 = 0.0287, ndcg@5 = 0.0175, hr@20 = 0.0758, ndcg@20 = 0.0307, hr@50 = 0.1370, ndcg@50 = 0.0428                   \u001b[0m\n",
            "2023-12-12 04:53:10.016350: Model Saved: tem\n",
            "\n",
            "2023-12-12 04:55:15.907267: Epoch 13/20, Train: loss = -96.9197, loss_main = 0.8535, loss_reco = -97.7331, loss_mask = -0.4927                   \n",
            "Test result: h5=0.0273 n5=0.0166 h10=0.0484 n10=0.0233 h20=0.0781 n20=0.0308 h50=0.1376 n50=0.0426\n",
            "2023-12-12 04:58:45.644172: Epoch 13/20, Test: hr@10 = 0.0484, ndcg@10 = 0.0233, hr@5 = 0.0273, ndcg@5 = 0.0166, hr@20 = 0.0781, ndcg@20 = 0.0308, hr@50 = 0.1376, ndcg@50 = 0.0426                   \n",
            "\n",
            "2023-12-12 05:00:51.186048: Epoch 14/20, Train: loss = -97.1290, loss_main = 0.8493, loss_reco = -97.9458, loss_mask = -0.4112                   \n",
            "Test result: h5=0.0273 n5=0.0168 h10=0.0470 n10=0.0231 h20=0.0772 n20=0.0307 h50=0.1408 n50=0.0432\n",
            "2023-12-12 05:04:23.341958: Epoch 14/20, Test: hr@10 = 0.0470, ndcg@10 = 0.0231, hr@5 = 0.0273, ndcg@5 = 0.0168, hr@20 = 0.0772, ndcg@20 = 0.0307, hr@50 = 0.1408, ndcg@50 = 0.0432                   \n",
            "\n",
            "2023-12-12 05:06:33.555250: Epoch 15/20, Train: loss = -97.3927, loss_main = 0.8479, loss_reco = -98.1863, loss_mask = -0.6494                   \n",
            "Test result: h5=0.0271 n5=0.0161 h10=0.0489 n10=0.0232 h20=0.0775 n20=0.0303 h50=0.1402 n50=0.0427\n",
            "2023-12-12 05:10:01.929723: Epoch 15/20, Test: hr@10 = 0.0489, ndcg@10 = 0.0232, hr@5 = 0.0271, ndcg@5 = 0.0161, hr@20 = 0.0775, ndcg@20 = 0.0303, hr@50 = 0.1402, ndcg@50 = 0.0427                   \n",
            "\n",
            "2023-12-12 05:12:15.710658: Epoch 16/20, Train: loss = -98.0617, loss_main = 0.8444, loss_reco = -98.8521, loss_mask = -0.6462                   \n",
            "Test result: h5=0.0285 n5=0.0175 h10=0.0492 n10=0.0241 h20=0.0779 n20=0.0313 h50=0.1404 n50=0.0436\n",
            "2023-12-12 05:15:44.163636: Epoch 16/20, Test: hr@10 = 0.0492, ndcg@10 = 0.0241, hr@5 = 0.0285, ndcg@5 = 0.0175, hr@20 = 0.0779, ndcg@20 = 0.0313, hr@50 = 0.1404, ndcg@50 = 0.0436                   \n",
            "\n",
            "2023-12-12 05:17:53.293477: Epoch 17/20, Train: loss = -97.8221, loss_main = 0.8367, loss_reco = -98.6049, loss_mask = -0.6462                   \n",
            "Test result: h5=0.0284 n5=0.0173 h10=0.0485 n10=0.0238 h20=0.0786 n20=0.0313 h50=0.1443 n50=0.0443\n",
            "2023-12-12 05:21:17.607501: Epoch 17/20, Test: hr@10 = 0.0485, ndcg@10 = 0.0238, hr@5 = 0.0284, ndcg@5 = 0.0173, hr@20 = 0.0786, ndcg@20 = 0.0313, hr@50 = 0.1443, ndcg@50 = 0.0443                   \n",
            "\n",
            "2023-12-12 05:23:18.035893: Epoch 18/20, Train: loss = -98.2927, loss_main = 0.8357, loss_reco = -99.1038, loss_mask = -0.3284                   \n",
            "Test result: h5=0.0281 n5=0.0167 h10=0.0486 n10=0.0232 h20=0.0774 n20=0.0304 h50=0.1443 n50=0.0436\n",
            "2023-12-12 05:26:46.030138: Epoch 18/20, Test: hr@10 = 0.0486, ndcg@10 = 0.0232, hr@5 = 0.0281, ndcg@5 = 0.0167, hr@20 = 0.0774, ndcg@20 = 0.0304, hr@50 = 0.1443, ndcg@50 = 0.0436                   \n",
            "\n",
            "2023-12-12 05:28:51.240891: Epoch 19/20, Train: loss = -98.2502, loss_main = 0.8346, loss_reco = -99.0388, loss_mask = -0.5622                   \n",
            "Test result: h5=0.0278 n5=0.0166 h10=0.0485 n10=0.0233 h20=0.0788 n20=0.0309 h50=0.1449 n50=0.0439\n",
            "2023-12-12 05:32:20.104254: Epoch 19/20, Test: hr@10 = 0.0485, ndcg@10 = 0.0233, hr@5 = 0.0278, ndcg@5 = 0.0166, hr@20 = 0.0788, ndcg@20 = 0.0309, hr@50 = 0.1449, ndcg@50 = 0.0439                   \n",
            "\n",
            "Test result: h5=0.0278 n5=0.0166 h10=0.0485 n10=0.0233 h20=0.0788 n20=0.0309 h50=0.1449 n50=0.0439\n",
            "2023-12-12 05:35:47.970547: Epoch 20/20, Test: hr@10 = 0.0485, ndcg@10 = 0.0233, hr@5 = 0.0278, ndcg@5 = 0.0166, hr@20 = 0.0788, ndcg@20 = 0.0309, hr@50 = 0.1449, ndcg@50 = 0.0439                   \n",
            "\u001b[1m2023-12-12 05:35:47.970588: Epoch 20/20, Best Result: hr@10 = 0.0495, ndcg@10 = 0.0241, hr@5 = 0.0287, ndcg@5 = 0.0175, hr@20 = 0.0758, ndcg@20 = 0.0307, hr@50 = 0.1370, ndcg@50 = 0.0428                   \u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!python main.py --data beauty"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "cell_execution_strategy": "setup",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
